---
title: "Homework #2"
output: github_document
---
```{r}
library(tidyverse)
```

# Problem 1
## Importing and Cleaning Data
```{r}
transit_df = read_csv("./data/NYC_Transit.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = as.integer(entry),
    entry = 
      case_match(
        entry,
        1 ~ "YES", 
        2 ~ "NO")
      )
transit_df
```

```{r}

info1_tbl = tibble(
  distinct_stations = distinct(transit_df, station_name)
)

```

```{r}
info2_tbl = tibble(
  compliant = filter(transit_df, ada == TRUE)
)
```

```{r}
info3_tbl = tibble(
  vendor_entrance = filter(transit_df, vending == "NO" & entry == "YES")
)
```


## Description
This data set contains information about the types of subway stations available in New York City, the locations of these stations, the type of entrances, ADA accessibility, and whether or not there is vending. This data set includes `r nrow(info1_tbl)` distinct stations.There are `r nrow(info2_tbl)` ADA compliant stations. There are `r nrow(info3_tbl)` stations without vending that allow entrance. 

```{r}
transit_2_df = mutate(
  transit_df,
  route8 = as.character(route8),
  route9 = as.character(route9),
  route10 = as.character(route10),
  route11 = as.character(route11)
) %>% 
  pivot_longer(
  route1:route11,
  names_to = "Route Number",
  values_to = "Route Name"
)

a_count = distinct(transit_2_df, station_name) %>% 
  filter("Route Name" == "A")
  
```

The number of distinct stations that serve the A train is `r nrow(a_count)`.




# Problem #2

## Reading and Cleaning the Data

```{r}
library(readxl)
```

```{r}
trash_wheel_df = read_excel("./data/trash_wheel_data.xlsx") %>% 
  janitor::clean_names() %>% 
  select (-month, -year, -date, -x15, -x16) %>% 
  filter(dumpster >= 1) %>% 
  mutate(
    sb = as.integer(sports_balls),
    sports_balls = sb
  )
trash_wheel_df
```

## Professor Trash Wheel and Gwynnda

```{r}
Prof_trash_wheel_df = readxl::read_excel("./data/trash_wheel_data.xlsx", sheet = "Professor Trash Wheel",  na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  filter(dumpster >= 1) %>% 
  mutate(
    prof_trash = "Professor Trash Wheel"
  )

Gwynnda_df = readxl::read_excel("./data/trash_wheel_data.xlsx", sheet = "Gwynnda Trash Wheel",  na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  filter(dumpster >= 1) %>% 
  mutate(
    prof_trash = "Gwynnda"
  )

two_trash_wheel = 
  full_join(Prof_trash_wheel_df, Gwynnda_df) %>% 
  relocate(prof_trash)
```

```{r}
prof_weight = filter(two_trash_wheel, prof_trash == "Professor Trash Wheel")

cigarette_june = filter(two_trash_wheel, prof_trash == "Gwynnda" & month == "June" & year == "2022")
```


## Describing the data

The data set "two_trash_wheels" contains data on trash collected by type for each dumpster, and states the month and year in which they were collected. The total weight of trash collected by professor trash wheel is `r sum(prof_weight$weight_tons, na.rm = TRUE)`. The total number of cigarette butts collected by Gwynnda in June 2022 is `r sum(cigarette_june$cigarette_butts, na.rm = TRUE)`. 

# Problem 3

## Reading in the data and cleaning

```{r}
bakers_df = read_csv("./data/bakers.csv", na = c("NA", ".", ""), show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  relocate(series) %>% 
  arrange(series, .by_group = FALSE)

bakes_df = read_csv("./data/bakes.csv", na = c("NA", ".", ""), show_col_types = FALSE)%>% 
  janitor::clean_names() 

results_df = read_csv("./data/results.csv", na = c("NA", ".", ""), show_col_types = FALSE)%>% 
  janitor::clean_names() %>% 
  rename("series" = x1,"episode" = x2, "baker" = x3, "technical" = x4, "results" = in_stayed_in_out_eliminated_star_baker_star_baker_winner_series_winner_runner_up_series_runner_up_wd_withdrew) %>% 
  filter(series >= 1 & series != "series") %>% 
  mutate(
    series = as.integer(series),
    episode = as.integer(episode),
    technical = as.integer(technical)
  )

```


## Combining and cleaning the data
```{r}
no_match_df = anti_join(bakers_df, bakes_df, by = NULL, copy = FALSE)
no_match2_df = anti_join(bakes_df, results_df, by = NULL, copy = FALSE)
no_match3_df = anti_join(bakers_df, results_df, by = NULL, copy = FALSE)

```

```{r}
clean_data_1 = left_join(bakers_df, bakes_df,  relationship = "many-to-many")

clean_data_final = left_join(clean_data_1, results_df) %>% 
  select(-baker) %>% 
  relocate(series, episode)
```

For this data set, I cleaned the data by converting all of the variable names to snake case. I noticed that, in comparison to the bakes and results data sets, the bakers data set was not in order. I fixed this by arranging the data in order of series, which also placed the bakers in alphabetical order. I also noticed that at the top of the data set for results, the column names were formatted strangely, so I renamed the columns and edited out columns that were blank. I also converted the variables "series", "episode", "baker", "technical", and "results" to integers to run the anti_join functions.

### Winner Table

```{r}
winners_df = filter(clean_data_final, results == "WINNER") %>% 
  select(baker_name, technical, results)

winners_df
```
The winners of the bake-off do not really surprise me, as all of them came within the top three for the technical challenge. 

### Viewers Info
```{r}
  viewers_df = read_csv("./data/viewers.csv", na = c("NA", ".", ""), show_col_types = FALSE) %>% 
  janitor::clean_names()

head(viewers_df, n = 10)
```

```{r}
viewership_1 = (sum(viewers_df$series_1, na.rm = TRUE)/nrow(viewers_df))

viewership_5 = (sum(viewers_df$series_5, na.rm = TRUE)/nrow(viewers_df))
```


The average viewership for Season 1 was `r viewership_1`. The average viewership for Season 5 was `r viewership_5`. 



